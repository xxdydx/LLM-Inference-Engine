# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: inference.proto
# Protobuf Python Version: 6.31.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    0,
    '',
    'inference.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0finference.proto\x12\tinference\"x\n\x0ePredictRequest\x12\x11\n\tinput_ids\x18\x01 \x03(\x05\x12\x12\n\nmax_tokens\x18\x02 \x01(\x05\x12\x11\n\tbeam_size\x18\x03 \x01(\x05\x12\x16\n\x0elength_penalty\x18\x04 \x01(\x02\x12\x14\n\x0c\x65os_token_id\x18\x05 \x01(\x05\"5\n\x0fPredictResponse\x12\x12\n\noutput_ids\x18\x01 \x03(\x05\x12\x0e\n\x06logits\x18\x02 \x03(\x02\"\x0f\n\rHealthRequest\"-\n\x0eHealthResponse\x12\n\n\x02ok\x18\x01 \x01(\x08\x12\x0f\n\x07message\x18\x02 \x01(\t\"\x10\n\x0eMetricsRequest\"\xe7\x02\n\x0fMetricsResponse\x12\x16\n\x0etotal_requests\x18\x01 \x01(\x05\x12\x15\n\rtotal_batches\x18\x02 \x01(\x05\x12\x16\n\x0e\x61vg_batch_size\x18\x03 \x01(\x02\x12\x18\n\x10\x62\x61tch_timeout_ms\x18\x04 \x01(\x05\x12\x16\n\x0emax_batch_size\x18\x05 \x01(\x05\x12\x1b\n\x13requests_per_second\x18\x06 \x01(\x02\x12\x19\n\x11\x61vg_batch_time_ms\x18\x07 \x01(\x02\x12\x19\n\x11quantization_type\x18\x08 \x01(\t\x12\x1d\n\x15\x61vg_inference_time_ms\x18\t \x01(\x02\x12\x1e\n\x16throughput_req_per_sec\x18\n \x01(\x02\x12\x18\n\x10total_inferences\x18\x0b \x01(\x05\x12\x18\n\x10kv_cache_enabled\x18\x0c \x01(\x08\x12\x15\n\rkv_cache_size\x18\r \x01(\x05\x32\xd8\x01\n\x10InferenceService\x12@\n\x07Predict\x12\x19.inference.PredictRequest\x1a\x1a.inference.PredictResponse\x12=\n\x06Health\x12\x18.inference.HealthRequest\x1a\x19.inference.HealthResponse\x12\x43\n\nGetMetrics\x12\x19.inference.MetricsRequest\x1a\x1a.inference.MetricsResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'inference_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_PREDICTREQUEST']._serialized_start=30
  _globals['_PREDICTREQUEST']._serialized_end=150
  _globals['_PREDICTRESPONSE']._serialized_start=152
  _globals['_PREDICTRESPONSE']._serialized_end=205
  _globals['_HEALTHREQUEST']._serialized_start=207
  _globals['_HEALTHREQUEST']._serialized_end=222
  _globals['_HEALTHRESPONSE']._serialized_start=224
  _globals['_HEALTHRESPONSE']._serialized_end=269
  _globals['_METRICSREQUEST']._serialized_start=271
  _globals['_METRICSREQUEST']._serialized_end=287
  _globals['_METRICSRESPONSE']._serialized_start=290
  _globals['_METRICSRESPONSE']._serialized_end=649
  _globals['_INFERENCESERVICE']._serialized_start=652
  _globals['_INFERENCESERVICE']._serialized_end=868
# @@protoc_insertion_point(module_scope)
