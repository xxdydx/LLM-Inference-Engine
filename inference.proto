syntax = "proto3";

package inference;

// Inference service definition
service InferenceService {
  // Predict endpoint for text generation
  rpc Predict(PredictRequest) returns (PredictResponse);
  
  // Health check endpoint
  rpc Health(HealthRequest) returns (HealthResponse);
  
  // Get metrics endpoint
  rpc GetMetrics(MetricsRequest) returns (MetricsResponse);
}

// Request message for prediction
message PredictRequest {
  repeated int32 input_ids = 1;
  int32 max_tokens = 2;
}

// Response message for prediction
message PredictResponse {
  repeated int32 output_ids = 1;
  repeated float logits = 2;
}

// Health check request
message HealthRequest {
  // Empty message for health check
}

// Health check response
message HealthResponse {
  bool ok = 1;
  string message = 2;
} 

// Metrics request
message MetricsRequest {
  // Empty message for metrics request
}

// Metrics response
message MetricsResponse {
  int32 total_requests = 1;
  int32 total_batches = 2;
  float avg_batch_size = 3;
  int32 batch_timeout_ms = 4;
  int32 max_batch_size = 5;
  float requests_per_second = 6;
  float avg_batch_time_ms = 7;
}